{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LANGCHAIN_PROJECT=rag_book_02\n"
     ]
    }
   ],
   "source": [
    "%env LANGCHAIN_PROJECT=rag_book_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "            azure_deployment=os.getenv(\"OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "            openai_api_type=\"azure\",\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "            deployment=os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "            chunk_size=1,\n",
    "            embedding_ctx_length=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple example dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"What's the name of the singer?\",\n",
    "            \"documents\": [\n",
    "                {\n",
    "                    \"metadata\": {},\n",
    "                    \"page_content\": \"the long - awaited moment arrives. the moon is high in the sky, the stars are shining like diamonds, and the whole audience is excited! the band takes the stage... our friends play and have a blast. they are partying, jumping, and dancing! fred sings happily because all his friends are with him on this special day. the night is so magical in the forest of starry sky!\\nhis great friend alfred von jurgen, known as vj, is among the very first to receive the invitation. vj is a hazel bear descended from the noble bear families of the north. he has explored many lands and learned ancient bear dialects. he is the most technologically advanced bear in his family because he studied at a. i. t., the famous animal institute of technology. in this school, he learned the secrets of the compu ter world and electronic music.\\n\\\" original story conceived and written by elfi e lupi. the images have been modified based on images generated by artificial intelligence..\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"label\": \"Fred is the singer.\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"What's the name of the forrest?\",\n",
    "            \"documents\": [\n",
    "                {\n",
    "                    \"metadata\": {},\n",
    "                    \"page_content\": \"once upon a time, there was an enchanted forest called starry sky, inhabited by many cute and funny animals. along its paths, from all corners of the world, par rots, giraffes, sheep, bears, and many other furry and fea thered friends found shelter. the forest embraced them with its branches, offering them warm shelter and many new friends. its magic? giving animals happy days, full of surprises and ne w adventures.\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"label\": \"Starry Sky\",\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"ds-rag-eval\"\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[e[\"inputs\"] for e in examples], \n",
    "    outputs=[e[\"outputs\"] for e in examples],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import chat_models, prompts\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "class MyRetriever(BaseRetriever):\n",
    "    def _get_relevant_documents(self, query, *, run_manager):\n",
    "        return [Document(page_content=\"Example\")]\n",
    "\n",
    "# THIS IS EVALUATED \n",
    "response_synthesizer = (\n",
    "    prompts.ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Respond using the following documents as context:\\n{documents}\"),\n",
    "            (\"user\", \"{question}\")\n",
    "        ]\n",
    "    ) | model\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"documents\": MyRetriever(),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | response_synthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import RunEvaluator, EvaluationResult\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "class FaithfulnessEvaluator(RunEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.evaluator = load_evaluator(\n",
    "            \"labeled_score_string\", \n",
    "            criteria={\"faithful\": \"How faithful is the submission to the reference context?\"},\n",
    "            normalize_by=10,\n",
    "            llm=model,\n",
    "        )\n",
    "\n",
    "    def evaluate_run(self, run, example) -> EvaluationResult:\n",
    "        res = self.evaluator.evaluate_strings(\n",
    "            prediction=next(iter(run.outputs.values())),\n",
    "            input=run.inputs[\"question\"],\n",
    "            # We are treating the documents as the reference context in this case.\n",
    "            reference=example.inputs[\"documents\"],\n",
    "        )\n",
    "        return EvaluationResult(key=\"labeled_criteria:faithful\", **res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'aching-doctor-6' at:\n",
      "https://smith.langchain.com/o/1a3b231d-e8b9-4837-8416-2403db894308/datasets/a2f55d1e-77d5-4fb7-b659-343a543315bf/compare?selectedSessions=76274d2c-511b-4461-998b-a983a4c786e8\n",
      "\n",
      "View all tests for Dataset ds-rag-eval at:\n",
      "https://smith.langchain.com/o/1a3b231d-e8b9-4837-8416-2403db894308/datasets/a2f55d1e-77d5-4fb7-b659-343a543315bf\n",
      "[------------------------------------------------->] 2/2"
     ]
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    eval_llm=model,\n",
    "    evaluators=[\"qa\"],\n",
    "    custom_evaluators=[FaithfulnessEvaluator()],\n",
    "    input_key=\"question\",\n",
    ")\n",
    "results = client.run_on_dataset(\n",
    "    llm_or_chain_factory=response_synthesizer,\n",
    "    dataset_name=dataset_name,\n",
    "    evaluation=eval_config,\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PERSISTENT_DIR = \"../../data/chroma\"\n",
    "CHROMA_COLLECTION_NAME = \"book_eng\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "            collection_name=CHROMA_COLLECTION_NAME,\n",
    "            persist_directory=CHROMA_PERSISTENT_DIR,\n",
    "            embedding_function=embeddings,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 3, \"score_threshold\": 0.9})\n",
    "#retriever.get_relevant_documents(\"What's the name of the singer?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import chat_models, prompts\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "class MyRetriever(BaseRetriever):\n",
    "    def _get_relevant_documents(self, query, *, run_manager):\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 3, \"score_threshold\": 0.9})        \n",
    "        return retriever.get_relevant_documents(query)\n",
    "        \n",
    "\n",
    "# This is what we will evaluate\n",
    "response_synthesizer = (\n",
    "    prompts.ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Respond using the following documents as context:\\n{documents}\"),\n",
    "            (\"user\", \"{question}\")\n",
    "        ]\n",
    "    ) | model\n",
    ")\n",
    "\n",
    "# Full chain below for illustration\n",
    "chain = (\n",
    "    {\n",
    "        \"documents\": MyRetriever(),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | response_synthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The name of the singer is Fred.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's the name of the singer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to rag eval\n",
    "{\n",
    "  \"label\": \"Starry Sky\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-articles-wuG-FtGG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
